{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "autoencoders_detailed.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "LQ7i1HkmYY68",
        "qA5xi_AvRjrU",
        "M-KAfd5pLCBS"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQ7i1HkmYY68",
        "colab_type": "text"
      },
      "source": [
        "# Autoencoders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rYVufslYY7D",
        "colab_type": "text"
      },
      "source": [
        "В этом ноутбуке мы будем тренировать автоэнкодеры кодировать лица людей. Для этого возьмем следующий датасет: \"Labeled Faces in the Wild\" (LFW) (http://vis-www.cs.umass.edu/lfw/). Код для скачивания и загрузки датасета написан за вас в файле get_dataset.py\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wru2LNFuL2Iq",
        "colab_type": "text"
      },
      "source": [
        "# Vanilla Autoencoder (3 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kr3STtdpYY7G",
        "colab_type": "text"
      },
      "source": [
        "## Prepare the data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6H9t8Te4QL2",
        "colab_type": "code",
        "outputId": "78f8990f-229b-4314-e11b-0bbe9ed6601e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install Pillow"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (7.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0DNtxl54S3Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4c6e1506-148a-4c8e-e1f6-d4496b52ee50"
      },
      "source": [
        "!pip install"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: You must give at least one requirement to install (see \"pip help install\")\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTNi9JLRYY7I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from copy import deepcopy\n",
        "import torch.utils.data as data_utils\n",
        "from torchsummary import summary\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "from torchvision import transforms, datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3KhlblLYY7P",
        "colab_type": "code",
        "outputId": "03b7fafb-3644-43de-eac3-2d41aea9976e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "# The following line fetches you two datasets: images, usable for autoencoder training and attributes.\n",
        "# Those attributes will be required for the final part of the assignment (applying smiles), so please keep them in mind\n",
        "from get_dataset_correct import fetch_dataset\n",
        "data, attrs = fetch_dataset()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n",
            "attributes not found, downloading...\n",
            "done\n",
            "45 45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oW_Jsi42YY7T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMAGE_H = data.shape[1]\n",
        "IMAGE_W = data.shape[2]\n",
        "# у нас цветные изображения\n",
        "N_CHANNELS = 3\n",
        "\n",
        "TRAIN_SIZE = 10000\n",
        "VAL_SIZE = data.shape[0] - TRAIN_SIZE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MSzXXGoYY7X",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Разбейте выборку картинок на train и val и приведите значения элементов в интервал [0, 1] типа float"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjV-kGgwRGIw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AutoEncode(Dataset):\n",
        "  def __init__(self, data):\n",
        "    super().__init__()\n",
        "    self.data = data\n",
        "    self.len_ = len(data)\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "        return self.len_\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "    X = np.array(self.data[index]/255., dtype = 'float32')\n",
        "    return transform(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "el-qVrA_TLk2",
        "colab_type": "code",
        "outputId": "42ad4725-6954-4bce-e6d0-5088017afe1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train, X_val = train_test_split(data, train_size=TRAIN_SIZE)\n",
        "print(X_train.shape, X_val.shape)\n",
        "X_train = AutoEncode(X_train)\n",
        "X_val = AutoEncode(X_val)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 45, 45, 3) (3143, 45, 45, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "dFc8lTm_YY7Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "964d74c8-cac3-4856-958f-0fd1a0bc5257"
      },
      "source": [
        "'''data = data.transpose(0, 3, 1, 2) #переводим в тензорный вид (batch, C, H, W)\n",
        "transform = transforms.ToTensor()\n",
        "X_train = np.float32(data[:10000]/255.) # приводим к [0, 1], transforms.ToTensor() сделает это все за нас\n",
        "X_val = np.float32(data[10000:]/255.)'''"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'data = data.transpose(0, 3, 1, 2) #переводим в тензорный вид (batch, C, H, W)\\ntransform = transforms.ToTensor()\\nX_train = np.float32(data[:10000]/255.) # приводим к [0, 1], transforms.ToTensor() сделает это все за нас\\nX_val = np.float32(data[10000:]/255.)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRPicfzZ-E0T",
        "colab_type": "text"
      },
      "source": [
        "Посмотрим первые 5 аттрибутов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWwkUXjf9mVa",
        "colab_type": "code",
        "outputId": "e9dee444-b4d2-4d75-8206-0b2e27c385f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "attrs.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Male</th>\n",
              "      <th>Asian</th>\n",
              "      <th>White</th>\n",
              "      <th>Black</th>\n",
              "      <th>Baby</th>\n",
              "      <th>Child</th>\n",
              "      <th>Youth</th>\n",
              "      <th>Middle Aged</th>\n",
              "      <th>Senior</th>\n",
              "      <th>Black Hair</th>\n",
              "      <th>Blond Hair</th>\n",
              "      <th>Brown Hair</th>\n",
              "      <th>Bald</th>\n",
              "      <th>No Eyewear</th>\n",
              "      <th>Eyeglasses</th>\n",
              "      <th>Sunglasses</th>\n",
              "      <th>Mustache</th>\n",
              "      <th>Smiling</th>\n",
              "      <th>Frowning</th>\n",
              "      <th>Chubby</th>\n",
              "      <th>Blurry</th>\n",
              "      <th>Harsh Lighting</th>\n",
              "      <th>Flash</th>\n",
              "      <th>Soft Lighting</th>\n",
              "      <th>Outdoor</th>\n",
              "      <th>Curly Hair</th>\n",
              "      <th>Wavy Hair</th>\n",
              "      <th>Straight Hair</th>\n",
              "      <th>Receding Hairline</th>\n",
              "      <th>Bangs</th>\n",
              "      <th>Sideburns</th>\n",
              "      <th>Fully Visible Forehead</th>\n",
              "      <th>Partially Visible Forehead</th>\n",
              "      <th>Obstructed Forehead</th>\n",
              "      <th>Bushy Eyebrows</th>\n",
              "      <th>Arched Eyebrows</th>\n",
              "      <th>Narrow Eyes</th>\n",
              "      <th>Eyes Open</th>\n",
              "      <th>Big Nose</th>\n",
              "      <th>Pointy Nose</th>\n",
              "      <th>Big Lips</th>\n",
              "      <th>Mouth Closed</th>\n",
              "      <th>Mouth Slightly Open</th>\n",
              "      <th>Mouth Wide Open</th>\n",
              "      <th>Teeth Not Visible</th>\n",
              "      <th>No Beard</th>\n",
              "      <th>Goatee</th>\n",
              "      <th>Round Jaw</th>\n",
              "      <th>Double Chin</th>\n",
              "      <th>Wearing Hat</th>\n",
              "      <th>Oval Face</th>\n",
              "      <th>Square Face</th>\n",
              "      <th>Round Face</th>\n",
              "      <th>Color Photo</th>\n",
              "      <th>Posed Photo</th>\n",
              "      <th>Attractive Man</th>\n",
              "      <th>Attractive Woman</th>\n",
              "      <th>Indian</th>\n",
              "      <th>Gray Hair</th>\n",
              "      <th>Bags Under Eyes</th>\n",
              "      <th>Heavy Makeup</th>\n",
              "      <th>Rosy Cheeks</th>\n",
              "      <th>Shiny Skin</th>\n",
              "      <th>Pale Skin</th>\n",
              "      <th>5 o' Clock Shadow</th>\n",
              "      <th>Strong Nose-Mouth Lines</th>\n",
              "      <th>Wearing Lipstick</th>\n",
              "      <th>Flushed Face</th>\n",
              "      <th>High Cheekbones</th>\n",
              "      <th>Brown Eyes</th>\n",
              "      <th>Wearing Earrings</th>\n",
              "      <th>Wearing Necktie</th>\n",
              "      <th>Wearing Necklace</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.56835</td>\n",
              "      <td>-1.88904</td>\n",
              "      <td>1.7372</td>\n",
              "      <td>-0.929729</td>\n",
              "      <td>-1.4718</td>\n",
              "      <td>-0.19558</td>\n",
              "      <td>-0.835609</td>\n",
              "      <td>-0.351468</td>\n",
              "      <td>-1.01253</td>\n",
              "      <td>-0.719593</td>\n",
              "      <td>-0.632401</td>\n",
              "      <td>0.464839</td>\n",
              "      <td>-0.973528</td>\n",
              "      <td>1.56519</td>\n",
              "      <td>-1.2967</td>\n",
              "      <td>-1.54272</td>\n",
              "      <td>-0.684671</td>\n",
              "      <td>-0.86499</td>\n",
              "      <td>0.766886</td>\n",
              "      <td>-0.218952</td>\n",
              "      <td>-1.65567</td>\n",
              "      <td>-0.787044</td>\n",
              "      <td>-0.599665</td>\n",
              "      <td>0.458519</td>\n",
              "      <td>0.18976</td>\n",
              "      <td>0.851555</td>\n",
              "      <td>-0.38572</td>\n",
              "      <td>-0.497719</td>\n",
              "      <td>-0.161149</td>\n",
              "      <td>-0.257514</td>\n",
              "      <td>-0.0888388</td>\n",
              "      <td>0.455469</td>\n",
              "      <td>-0.839211</td>\n",
              "      <td>-0.0229481</td>\n",
              "      <td>-0.922568</td>\n",
              "      <td>-0.114539</td>\n",
              "      <td>1.46122</td>\n",
              "      <td>1.75848</td>\n",
              "      <td>0.0688935</td>\n",
              "      <td>1.26786</td>\n",
              "      <td>-1.12024</td>\n",
              "      <td>0.917617</td>\n",
              "      <td>-1.30796</td>\n",
              "      <td>-1.50041</td>\n",
              "      <td>1.02922</td>\n",
              "      <td>0.832363</td>\n",
              "      <td>-0.498657</td>\n",
              "      <td>0.251365</td>\n",
              "      <td>-0.705281</td>\n",
              "      <td>-0.515715</td>\n",
              "      <td>0.374239</td>\n",
              "      <td>-0.168675</td>\n",
              "      <td>-0.614143</td>\n",
              "      <td>3.0977</td>\n",
              "      <td>1.52386</td>\n",
              "      <td>0.779278</td>\n",
              "      <td>-0.0714539</td>\n",
              "      <td>-1.24648</td>\n",
              "      <td>-0.769283</td>\n",
              "      <td>-0.725597</td>\n",
              "      <td>-1.82061</td>\n",
              "      <td>-2.07298</td>\n",
              "      <td>-0.960759</td>\n",
              "      <td>0.361738</td>\n",
              "      <td>1.16612</td>\n",
              "      <td>-1.16492</td>\n",
              "      <td>-1.13999</td>\n",
              "      <td>-2.37175</td>\n",
              "      <td>-1.29993</td>\n",
              "      <td>-0.414682</td>\n",
              "      <td>-1.1449</td>\n",
              "      <td>0.694007</td>\n",
              "      <td>-0.826609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.169851</td>\n",
              "      <td>-0.982408</td>\n",
              "      <td>0.422709</td>\n",
              "      <td>-1.28218</td>\n",
              "      <td>-1.36006</td>\n",
              "      <td>-0.867002</td>\n",
              "      <td>-0.452293</td>\n",
              "      <td>-0.197521</td>\n",
              "      <td>-0.956073</td>\n",
              "      <td>-0.802107</td>\n",
              "      <td>-0.736883</td>\n",
              "      <td>0.294554</td>\n",
              "      <td>-1.27765</td>\n",
              "      <td>0.954771</td>\n",
              "      <td>-0.990992</td>\n",
              "      <td>-1.16736</td>\n",
              "      <td>-0.835146</td>\n",
              "      <td>0.798544</td>\n",
              "      <td>-0.971679</td>\n",
              "      <td>0.342826</td>\n",
              "      <td>-1.32256</td>\n",
              "      <td>0.962937</td>\n",
              "      <td>-1.19936</td>\n",
              "      <td>-0.157307</td>\n",
              "      <td>0.443224</td>\n",
              "      <td>-0.00288156</td>\n",
              "      <td>-0.0211584</td>\n",
              "      <td>-0.226563</td>\n",
              "      <td>-0.0810386</td>\n",
              "      <td>-0.827202</td>\n",
              "      <td>-0.106624</td>\n",
              "      <td>1.22759</td>\n",
              "      <td>-0.812223</td>\n",
              "      <td>-1.24126</td>\n",
              "      <td>0.0962725</td>\n",
              "      <td>-0.404544</td>\n",
              "      <td>0.325919</td>\n",
              "      <td>0.474452</td>\n",
              "      <td>1.13536</td>\n",
              "      <td>0.0587247</td>\n",
              "      <td>0.611176</td>\n",
              "      <td>-1.17251</td>\n",
              "      <td>0.428512</td>\n",
              "      <td>-0.874235</td>\n",
              "      <td>-1.19156</td>\n",
              "      <td>0.192359</td>\n",
              "      <td>-0.204166</td>\n",
              "      <td>0.342347</td>\n",
              "      <td>0.239512</td>\n",
              "      <td>-1.47469</td>\n",
              "      <td>0.236057</td>\n",
              "      <td>-0.565208</td>\n",
              "      <td>-0.712542</td>\n",
              "      <td>2.99708</td>\n",
              "      <td>-0.273306</td>\n",
              "      <td>-0.187722</td>\n",
              "      <td>-0.604608</td>\n",
              "      <td>-1.3217</td>\n",
              "      <td>-0.938559</td>\n",
              "      <td>0.494294</td>\n",
              "      <td>-0.659043</td>\n",
              "      <td>-1.14375</td>\n",
              "      <td>-0.775722</td>\n",
              "      <td>-0.832036</td>\n",
              "      <td>-0.39768</td>\n",
              "      <td>0.87416</td>\n",
              "      <td>-0.945431</td>\n",
              "      <td>-0.268649</td>\n",
              "      <td>-0.00624408</td>\n",
              "      <td>-0.0304057</td>\n",
              "      <td>-0.480128</td>\n",
              "      <td>0.66676</td>\n",
              "      <td>-0.496559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.997749</td>\n",
              "      <td>-1.36419</td>\n",
              "      <td>-0.157377</td>\n",
              "      <td>-0.756447</td>\n",
              "      <td>-1.89183</td>\n",
              "      <td>-0.871526</td>\n",
              "      <td>-0.862893</td>\n",
              "      <td>0.0314447</td>\n",
              "      <td>-1.34152</td>\n",
              "      <td>-0.0900375</td>\n",
              "      <td>-1.20073</td>\n",
              "      <td>-0.33246</td>\n",
              "      <td>-0.537006</td>\n",
              "      <td>1.29836</td>\n",
              "      <td>-1.49847</td>\n",
              "      <td>-1.28582</td>\n",
              "      <td>1.14174</td>\n",
              "      <td>0.172817</td>\n",
              "      <td>0.106412</td>\n",
              "      <td>-0.788843</td>\n",
              "      <td>0.349295</td>\n",
              "      <td>-1.64372</td>\n",
              "      <td>0.454287</td>\n",
              "      <td>1.18946</td>\n",
              "      <td>-0.688414</td>\n",
              "      <td>-0.590574</td>\n",
              "      <td>-0.266673</td>\n",
              "      <td>0.467224</td>\n",
              "      <td>0.567348</td>\n",
              "      <td>-1.7191</td>\n",
              "      <td>0.124667</td>\n",
              "      <td>1.60274</td>\n",
              "      <td>-0.659399</td>\n",
              "      <td>-1.75376</td>\n",
              "      <td>1.20447</td>\n",
              "      <td>0.0221884</td>\n",
              "      <td>-1.13544</td>\n",
              "      <td>1.70286</td>\n",
              "      <td>-0.422144</td>\n",
              "      <td>0.587859</td>\n",
              "      <td>0.414363</td>\n",
              "      <td>0.344447</td>\n",
              "      <td>-1.26045</td>\n",
              "      <td>-0.577746</td>\n",
              "      <td>0.405567</td>\n",
              "      <td>-1.91655</td>\n",
              "      <td>0.92126</td>\n",
              "      <td>0.247437</td>\n",
              "      <td>-0.428451</td>\n",
              "      <td>-0.772273</td>\n",
              "      <td>0.370673</td>\n",
              "      <td>-0.509596</td>\n",
              "      <td>-0.768482</td>\n",
              "      <td>1.7069</td>\n",
              "      <td>0.126524</td>\n",
              "      <td>-0.497001</td>\n",
              "      <td>-0.393042</td>\n",
              "      <td>-0.178307</td>\n",
              "      <td>-1.18023</td>\n",
              "      <td>-0.596914</td>\n",
              "      <td>-1.80538</td>\n",
              "      <td>-0.951643</td>\n",
              "      <td>-0.838087</td>\n",
              "      <td>1.54974</td>\n",
              "      <td>1.88475</td>\n",
              "      <td>-0.999765</td>\n",
              "      <td>-1.35986</td>\n",
              "      <td>-1.91211</td>\n",
              "      <td>-1.09563</td>\n",
              "      <td>0.915126</td>\n",
              "      <td>-0.572332</td>\n",
              "      <td>0.144262</td>\n",
              "      <td>-0.841231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.12272</td>\n",
              "      <td>-1.9978</td>\n",
              "      <td>1.91614</td>\n",
              "      <td>-2.51421</td>\n",
              "      <td>-2.58007</td>\n",
              "      <td>-1.40424</td>\n",
              "      <td>0.0575511</td>\n",
              "      <td>0.000195882</td>\n",
              "      <td>-1.27351</td>\n",
              "      <td>-1.43146</td>\n",
              "      <td>-0.0705188</td>\n",
              "      <td>-0.339239</td>\n",
              "      <td>-2.00415</td>\n",
              "      <td>0.665695</td>\n",
              "      <td>-0.77594</td>\n",
              "      <td>-1.47163</td>\n",
              "      <td>-1.17908</td>\n",
              "      <td>0.563327</td>\n",
              "      <td>-0.664429</td>\n",
              "      <td>-1.40793</td>\n",
              "      <td>0.435594</td>\n",
              "      <td>-0.589988</td>\n",
              "      <td>-1.6035</td>\n",
              "      <td>1.17074</td>\n",
              "      <td>0.760103</td>\n",
              "      <td>0.211498</td>\n",
              "      <td>-0.51618</td>\n",
              "      <td>-1.33115</td>\n",
              "      <td>0.20284</td>\n",
              "      <td>0.149645</td>\n",
              "      <td>-0.0464296</td>\n",
              "      <td>0.640885</td>\n",
              "      <td>-0.107616</td>\n",
              "      <td>-0.831271</td>\n",
              "      <td>-0.827005</td>\n",
              "      <td>-0.588725</td>\n",
              "      <td>0.429255</td>\n",
              "      <td>1.58766</td>\n",
              "      <td>0.499086</td>\n",
              "      <td>-0.0568692</td>\n",
              "      <td>-0.866643</td>\n",
              "      <td>-0.959689</td>\n",
              "      <td>0.35073</td>\n",
              "      <td>-1.33535</td>\n",
              "      <td>-0.42789</td>\n",
              "      <td>0.826817</td>\n",
              "      <td>-0.256779</td>\n",
              "      <td>0.149751</td>\n",
              "      <td>-1.20153</td>\n",
              "      <td>-1.08392</td>\n",
              "      <td>0.255363</td>\n",
              "      <td>-0.650423</td>\n",
              "      <td>-0.506293</td>\n",
              "      <td>1.10159</td>\n",
              "      <td>0.640783</td>\n",
              "      <td>1.57503</td>\n",
              "      <td>-0.484397</td>\n",
              "      <td>-1.55968</td>\n",
              "      <td>-1.43712</td>\n",
              "      <td>0.379363</td>\n",
              "      <td>-0.648233</td>\n",
              "      <td>-2.25735</td>\n",
              "      <td>-1.07561</td>\n",
              "      <td>0.567822</td>\n",
              "      <td>-0.176089</td>\n",
              "      <td>1.10812</td>\n",
              "      <td>-1.60094</td>\n",
              "      <td>-3.26461</td>\n",
              "      <td>0.813418</td>\n",
              "      <td>0.308631</td>\n",
              "      <td>-0.848693</td>\n",
              "      <td>0.475941</td>\n",
              "      <td>-0.447025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.07821</td>\n",
              "      <td>-2.0081</td>\n",
              "      <td>1.67621</td>\n",
              "      <td>-2.27806</td>\n",
              "      <td>-2.65185</td>\n",
              "      <td>-1.34841</td>\n",
              "      <td>0.649089</td>\n",
              "      <td>0.0176564</td>\n",
              "      <td>-1.88911</td>\n",
              "      <td>-1.85721</td>\n",
              "      <td>-0.568057</td>\n",
              "      <td>0.840375</td>\n",
              "      <td>-1.98127</td>\n",
              "      <td>1.66671</td>\n",
              "      <td>-0.910723</td>\n",
              "      <td>-1.99351</td>\n",
              "      <td>-0.871335</td>\n",
              "      <td>0.507786</td>\n",
              "      <td>-0.488947</td>\n",
              "      <td>-0.88649</td>\n",
              "      <td>-0.990132</td>\n",
              "      <td>-0.750813</td>\n",
              "      <td>-0.378479</td>\n",
              "      <td>0.583086</td>\n",
              "      <td>-1.4796</td>\n",
              "      <td>0.250185</td>\n",
              "      <td>-0.381123</td>\n",
              "      <td>-0.611991</td>\n",
              "      <td>-0.143091</td>\n",
              "      <td>-1.07276</td>\n",
              "      <td>0.432094</td>\n",
              "      <td>1.08919</td>\n",
              "      <td>-0.470929</td>\n",
              "      <td>-1.17712</td>\n",
              "      <td>-0.111313</td>\n",
              "      <td>-0.154603</td>\n",
              "      <td>-1.03151</td>\n",
              "      <td>2.39246</td>\n",
              "      <td>-0.191576</td>\n",
              "      <td>1.2279</td>\n",
              "      <td>-1.3818</td>\n",
              "      <td>-1.52885</td>\n",
              "      <td>0.907964</td>\n",
              "      <td>-1.32429</td>\n",
              "      <td>-0.934644</td>\n",
              "      <td>0.686995</td>\n",
              "      <td>-0.149301</td>\n",
              "      <td>0.0336263</td>\n",
              "      <td>-0.911138</td>\n",
              "      <td>-1.24109</td>\n",
              "      <td>0.904177</td>\n",
              "      <td>-0.309967</td>\n",
              "      <td>-1.03889</td>\n",
              "      <td>3.75812</td>\n",
              "      <td>1.05837</td>\n",
              "      <td>1.50215</td>\n",
              "      <td>-0.649715</td>\n",
              "      <td>-1.07294</td>\n",
              "      <td>-1.77832</td>\n",
              "      <td>-0.0771244</td>\n",
              "      <td>-0.743271</td>\n",
              "      <td>-3.30071</td>\n",
              "      <td>-0.779219</td>\n",
              "      <td>-1.46147</td>\n",
              "      <td>-0.955283</td>\n",
              "      <td>0.119113</td>\n",
              "      <td>-1.12818</td>\n",
              "      <td>-3.16105</td>\n",
              "      <td>0.0826804</td>\n",
              "      <td>-0.439614</td>\n",
              "      <td>-0.359859</td>\n",
              "      <td>-0.760774</td>\n",
              "      <td>-0.410152</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Male     Asian  ... Wearing Necktie Wearing Necklace\n",
              "0   1.56835  -1.88904  ...        0.694007        -0.826609\n",
              "1  0.169851 -0.982408  ...         0.66676        -0.496559\n",
              "2  0.997749  -1.36419  ...        0.144262        -0.841231\n",
              "3   1.12272   -1.9978  ...        0.475941        -0.447025\n",
              "4   1.07821   -2.0081  ...       -0.760774        -0.410152\n",
              "\n",
              "[5 rows x 73 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MES0waD1YY7c",
        "colab_type": "text"
      },
      "source": [
        "Напишем вспомогательную функцию, которая будет выводить n_row $\\cdot$ n_col первых картинок в массиве images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3z2ZvgS0YY7d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_gallery(images, h, w, n_row=3, n_col=6):\n",
        "    \"\"\"Helper function to plot a gallery of portraits\"\"\"\n",
        "    plt.figure(figsize=(1.5 * n_col, 1.7 * n_row))\n",
        "    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
        "    for i in range(n_row * n_col):\n",
        "        plt.subplot(n_row, n_col, i + 1)\n",
        "        try:\n",
        "            plt.imshow(images[i].reshape((h, w, 3)), cmap=plt.cm.gray, vmin=-1, vmax=1, interpolation='nearest') #для отрисовки тензора перевести к numpy\n",
        "            plt.xticks(())\n",
        "            plt.yticks(())\n",
        "        except:\n",
        "            pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-yV79BQYY7g",
        "colab_type": "text"
      },
      "source": [
        "Осталось привести картинки к тензорам из PyTorch, чтобы можно было потом скармливать их автоэнкодеру: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H__1M-rKYY7h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#X_train = torch.FloatTensor(X_train)\n",
        "#X_val = torch.FloatTensor(X_val)\n",
        "train_loader = DataLoader(X_train, batch_size=64, shuffle=True) # дата решафлится каждую эпоху\n",
        "val_loader = DataLoader(X_val, batch_size=64, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8UsNrJQAqZv",
        "colab_type": "code",
        "outputId": "373c0512-a8a7-49c3-8f10-79b8b081574d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "next(iter(train_loader)).shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 3, 45, 45])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6TJZ4fRJnkj",
        "colab_type": "code",
        "outputId": "10ec988c-3f2b-4828-c7df-42261d475cfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(X_train)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "__main__.AutoEncode"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9CC-DUhYY7i",
        "colab_type": "text"
      },
      "source": [
        "## Autoencoder\n",
        "\n",
        "Why to use all this complicated formulaes and regularizations, what is the need for variational inference? To analyze the difference, let's first train just an autoencoder on the data:\n",
        "<img src=\"https://i.imgur.com/nVJAtMT.png\" alt=\"Autoencoder\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csrNCYh-YY7j",
        "colab_type": "code",
        "outputId": "bdcc44bd-234f-41e7-ed0b-256f8e136176",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "inp_size=X_train.shape[1]\n",
        "hid_size=250\n",
        "dimZ = 100"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-a388a29372cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minp_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mhid_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdimZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'AutoEncode' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fjr-N8AWee-k",
        "colab_type": "text"
      },
      "source": [
        "Реализуем autoencoder. Архитектуру (conv, fully-connected, ReLu, etc) можете выбирать сами. Экспериментируйте!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SjHNX-rYY7k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        #на вход (3, 45, 45) выход (6, 45, 45)\n",
        "        self.conv1_down = nn.Sequential(nn.Conv2d(3, 20, 3, padding=1),\n",
        "                                        nn.BatchNorm2d(20),\n",
        "                                        nn.LeakyReLU(0.2)\n",
        "        )\n",
        "        self.conv2_down = nn.Sequential(nn.Conv2d(20, 40, 3),\n",
        "                                        nn.BatchNorm2d(40),\n",
        "                                        nn.LeakyReLU(0.2),\n",
        "                                        nn.MaxPool2d(2) #21\n",
        "        ) \n",
        "        self.conv3_down = nn.Sequential(nn.Conv2d(40, 60, 3), #19\n",
        "                                        nn.BatchNorm2d(60),\n",
        "                                        nn.LeakyReLU(0.2),\n",
        "        )\n",
        "        self.pool = nn.MaxPool2d(2) #9\n",
        "        self.fc1 = nn.Linear(60*9*9, 250)\n",
        "        #выход 250\n",
        "        self.fc2 = nn.Sequential(nn.Linear(250, 60*9*9),\n",
        "                                 nn.LeakyReLU(0.2)\n",
        "        )\n",
        "        self.conv3_up = nn.Sequential(nn.ConvTranspose2d(60, 40, 3, stride=2),# формула size+(size-1) + (pad)*2 - (kernel-1), где pad = 0, если padding=2, 1, если 1, 2, если 0 и еще padding зависит от kernel (pad = 2 для 3, pad=3 для 4)\n",
        "                                      nn.LeakyReLU(0.2),\n",
        "                                      nn.Conv2d(40, 40, 3, padding=1),\n",
        "                                      nn.BatchNorm2d(40),\n",
        "                                      nn.LeakyReLU(0.2)\n",
        "\n",
        "        )\n",
        "        self.conv2_up = nn.Sequential(nn.ConvTranspose2d(40, 20, 3, stride = 1),\n",
        "                                      nn.BatchNorm2d(20),\n",
        "                                      nn.LeakyReLU(0.2),\n",
        "                                      nn.Conv2d(20, 20, 3, padding=1),\n",
        "                                      nn.BatchNorm2d(20),\n",
        "                                      nn.LeakyReLU(0.2)\n",
        "        )\n",
        "        self.conv1_up = nn.Sequential(nn.ConvTranspose2d(20, 3, 3, stride=2),\n",
        "                                      nn.BatchNorm2d(3),#batchnorm после relu попробовать\n",
        "                                      nn.LeakyReLU(0.2),\n",
        "                                      nn.Conv2d(3, 3, 3, padding=2),\n",
        "                                      nn.BatchNorm2d(3),\n",
        "                                      nn.LeakyReLU(0.2)\n",
        "        )\n",
        "\n",
        "\n",
        "    def encoder_(self, x):\n",
        "        self.conv1 = self.conv1_down(x)\n",
        "        self.conv2 = self.conv2_down(self.conv1)\n",
        "        self.conv3 = self.conv3_down(self.conv2)\n",
        "        latent_code = self.fc1(self.pool(self.conv3).view(x.size(0), -1))\n",
        "        return latent_code\n",
        "\n",
        "\n",
        "    def decoder_(self, z):\n",
        "        z = self.fc2(z).view(-1, 60, 9, 9)\n",
        "        z = self.conv3_up(z)\n",
        "        z = self.conv2_up(z)\n",
        "        z = self.conv1_up(z)\n",
        "        reconstruct = torch.sigmoid(z) \n",
        "        return reconstruct   \n",
        "\n",
        "    def forward(self, x):\n",
        "        encoder = self.encoder_(x)\n",
        "        decoder = self.decoder_(encoder)\n",
        "        return decoder, encoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpmS-1i0MRCI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_weights(m):\n",
        "    if type(m) == nn.Conv2d or type(m) == nn.ConvTranspose2d:\n",
        "      nn.init.xavier_uniform_(m.weight)\n",
        "\n",
        "class Autoencoder_2(nn.Module):\n",
        "    def __init__(self, latent=250):\n",
        "        super().__init__()\n",
        "        #на вход (3, 45, 45) выход (6, 45, 45)\n",
        "        self.conv1_down = nn.Sequential(nn.Conv2d(3, 20, 3, padding=1),\n",
        "                                        nn.BatchNorm2d(20),\n",
        "                                        nn.LeakyReLU(0.2),\n",
        "                                        nn.Conv2d(20, 40, 3, padding = 1),\n",
        "                                        nn.BatchNorm2d(40),\n",
        "                                        nn.LeakyReLU(0.2)\n",
        "        )\n",
        "        self.conv2_down = nn.Sequential(nn.Conv2d(40, 80, 3),\n",
        "                                        nn.BatchNorm2d(80),\n",
        "                                        nn.LeakyReLU(0.2),\n",
        "                                        nn.Conv2d(80, 100, 3, padding = 1),\n",
        "                                        nn.BatchNorm2d(100),\n",
        "                                        nn.LeakyReLU(0.2),\n",
        "                                        nn.MaxPool2d(2)\n",
        "        ) \n",
        "        self.conv3_down = nn.Sequential(nn.Conv2d(100, 150, 3),\n",
        "                                        nn.BatchNorm2d(150),\n",
        "                                        nn.LeakyReLU(0.2),\n",
        "                                        nn.Conv2d(150, 150, 3, padding=1),\n",
        "                                        nn.BatchNorm2d(150),\n",
        "                                        nn.LeakyReLU(0.2)\n",
        "        )\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.fc1 = nn.Linear(150*9*9, latent)\n",
        "        #выход 250\n",
        "        self.fc2 = nn.Sequential(nn.Linear(latent, 150*9*9),\n",
        "                                 nn.LeakyReLU(0.2)\n",
        "        )\n",
        "        self.conv3_up = nn.Sequential(nn.ConvTranspose2d(150, 100, 3, stride=2),\n",
        "                                      nn.BatchNorm2d(100),# формула size+(size-1) + (pad)*2 - (kernel-1), где pad = 0, если padding=2, 1, если 1, 2, если 0 и еще padding зависит от kernel (pad = 2 для 3, pad=3 для 4)\n",
        "                                      nn.LeakyReLU(0.2),\n",
        "                                      nn.Conv2d(100, 100, 3, padding=1),\n",
        "                                      nn.BatchNorm2d(100),\n",
        "                                      nn.LeakyReLU(0.2)\n",
        "\n",
        "        )\n",
        "        self.conv2_up = nn.Sequential(nn.ConvTranspose2d(100, 60, 3, stride = 1),\n",
        "                                      nn.BatchNorm2d(60),\n",
        "                                      nn.LeakyReLU(0.2),\n",
        "                                      nn.Conv2d(60, 60, 3, padding=1),\n",
        "                                      nn.BatchNorm2d(60),\n",
        "                                      nn.LeakyReLU(0.2)\n",
        "        )\n",
        "        self.conv1_up = nn.Sequential(nn.ConvTranspose2d(60, 30, 3, stride=1),\n",
        "                                      nn.BatchNorm2d(30),\n",
        "                                      nn.LeakyReLU(0.2),\n",
        "                                      nn.Conv2d(30, 30, 3, padding=1),\n",
        "                                      nn.BatchNorm2d(30),\n",
        "                                      nn.LeakyReLU(0.2),\n",
        "                                      nn.ConvTranspose2d(30, 15, 3, stride=2, padding = 1),\n",
        "                                      nn.BatchNorm2d(15),\n",
        "                                      nn.LeakyReLU(0.2),\n",
        "                                      nn.Conv2d(15, 9, 3, padding=1),\n",
        "                                      nn.BatchNorm2d(9),\n",
        "                                      nn.LeakyReLU(0.2)\n",
        "        )\n",
        "        self.out = nn.Conv2d(9, 3, 3, padding = 1)\n",
        "\n",
        "\n",
        "    def encoder_(self, x):\n",
        "        self.conv1 = self.conv1_down(x)\n",
        "        self.conv2 = self.conv2_down(self.conv1)\n",
        "        self.conv3 = self.conv3_down(self.conv2)\n",
        "        latent_code = torch.tanh(self.fc1(self.pool(self.conv3).view(x.size(0), -1)))\n",
        "        return latent_code\n",
        "\n",
        "\n",
        "    def decoder_(self, z):\n",
        "        z = self.fc2(z).view(-1, 150, 9, 9)\n",
        "        z = self.conv3_up(z)\n",
        "        z = self.conv2_up(z)\n",
        "        z = self.conv1_up(z)\n",
        "        reconstruct = torch.sigmoid(self.out(z)) \n",
        "        return reconstruct   \n",
        "\n",
        "    def forward(self, x):\n",
        "        encoder = self.encoder_(x)\n",
        "        decoder = self.decoder_(encoder)\n",
        "        return decoder, encoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73lg3bI2YY7m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "23ea5900-4fee-4c2f-f816-2b2647fd3fb8"
      },
      "source": [
        "#попробовать несколько оптимизаторов(Adam, AdamW ...)\n",
        "DEVICE = torch.device('cuda')\n",
        "autoencoder = Autoencoder_2().to(DEVICE)\n",
        "autoencoder.apply(init_weights)\n",
        "optimizer = optim.Adam(autoencoder.parameters())\n",
        "criterion = nn.MSELoss()\n",
        "summary(autoencoder, (3,45, 45))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 20, 45, 45]             560\n",
            "       BatchNorm2d-2           [-1, 20, 45, 45]              40\n",
            "         LeakyReLU-3           [-1, 20, 45, 45]               0\n",
            "            Conv2d-4           [-1, 40, 45, 45]           7,240\n",
            "       BatchNorm2d-5           [-1, 40, 45, 45]              80\n",
            "         LeakyReLU-6           [-1, 40, 45, 45]               0\n",
            "            Conv2d-7           [-1, 80, 43, 43]          28,880\n",
            "       BatchNorm2d-8           [-1, 80, 43, 43]             160\n",
            "         LeakyReLU-9           [-1, 80, 43, 43]               0\n",
            "           Conv2d-10          [-1, 100, 43, 43]          72,100\n",
            "      BatchNorm2d-11          [-1, 100, 43, 43]             200\n",
            "        LeakyReLU-12          [-1, 100, 43, 43]               0\n",
            "        MaxPool2d-13          [-1, 100, 21, 21]               0\n",
            "           Conv2d-14          [-1, 150, 19, 19]         135,150\n",
            "      BatchNorm2d-15          [-1, 150, 19, 19]             300\n",
            "        LeakyReLU-16          [-1, 150, 19, 19]               0\n",
            "           Conv2d-17          [-1, 150, 19, 19]         202,650\n",
            "      BatchNorm2d-18          [-1, 150, 19, 19]             300\n",
            "        LeakyReLU-19          [-1, 150, 19, 19]               0\n",
            "        MaxPool2d-20            [-1, 150, 9, 9]               0\n",
            "           Linear-21                  [-1, 250]       3,037,750\n",
            "           Linear-22                [-1, 12150]       3,049,650\n",
            "        LeakyReLU-23                [-1, 12150]               0\n",
            "  ConvTranspose2d-24          [-1, 100, 19, 19]         135,100\n",
            "      BatchNorm2d-25          [-1, 100, 19, 19]             200\n",
            "        LeakyReLU-26          [-1, 100, 19, 19]               0\n",
            "           Conv2d-27          [-1, 100, 19, 19]          90,100\n",
            "      BatchNorm2d-28          [-1, 100, 19, 19]             200\n",
            "        LeakyReLU-29          [-1, 100, 19, 19]               0\n",
            "  ConvTranspose2d-30           [-1, 60, 21, 21]          54,060\n",
            "      BatchNorm2d-31           [-1, 60, 21, 21]             120\n",
            "        LeakyReLU-32           [-1, 60, 21, 21]               0\n",
            "           Conv2d-33           [-1, 60, 21, 21]          32,460\n",
            "      BatchNorm2d-34           [-1, 60, 21, 21]             120\n",
            "        LeakyReLU-35           [-1, 60, 21, 21]               0\n",
            "  ConvTranspose2d-36           [-1, 30, 23, 23]          16,230\n",
            "      BatchNorm2d-37           [-1, 30, 23, 23]              60\n",
            "        LeakyReLU-38           [-1, 30, 23, 23]               0\n",
            "           Conv2d-39           [-1, 30, 23, 23]           8,130\n",
            "      BatchNorm2d-40           [-1, 30, 23, 23]              60\n",
            "        LeakyReLU-41           [-1, 30, 23, 23]               0\n",
            "  ConvTranspose2d-42           [-1, 15, 45, 45]           4,065\n",
            "      BatchNorm2d-43           [-1, 15, 45, 45]              30\n",
            "        LeakyReLU-44           [-1, 15, 45, 45]               0\n",
            "           Conv2d-45            [-1, 9, 45, 45]           1,224\n",
            "      BatchNorm2d-46            [-1, 9, 45, 45]              18\n",
            "        LeakyReLU-47            [-1, 9, 45, 45]               0\n",
            "           Conv2d-48            [-1, 3, 45, 45]             246\n",
            "================================================================\n",
            "Total params: 6,877,483\n",
            "Trainable params: 6,877,483\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.02\n",
            "Forward/backward pass size (MB): 18.24\n",
            "Params size (MB): 26.24\n",
            "Estimated Total Size (MB): 44.50\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bdxg_3WJYY7o",
        "colab_type": "text"
      },
      "source": [
        "Осталось написать код обучения автоэнкодера. При этом было бы неплохо в процессе иногда смотреть, как автоэнкодер реконструирует изображения на данном этапе обучения. Наример, после каждой эпохи (прогона train выборки через автоэекодер) можно смотреть, какие реконструкции получились для каких-то изображений val выборки.\n",
        "\n",
        "Подсказка: если x_val -- каринка, а reconstruction -- ее реконструкция автоэнкодером, то красиво вывести эту каритинку и ее реконструкцию можно с помощью функции plot_gallery вот так:\n",
        "\n",
        "*plot_gallery([x_val, reconstruction], image_h, image_w, n_row=1, n_col=2)*\n",
        "\n",
        "А, ну еще было бы неплохо выводить графики train и val лоссов в процессе тренировки =)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "3H3DOojrYY7o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm, tqdm_notebook\n",
        "from IPython.display import clear_output\n",
        "\n",
        "\n",
        "def train(val, train, epochs):\n",
        "  train_losses = []\n",
        "  val_losses = []\n",
        "  best_model_wts = autoencoder.state_dict()\n",
        "  best_loss = np.inf\n",
        "  for epoch in range(epochs):\n",
        "    loss_train_running = 0\n",
        "    total_train_data = 0\n",
        "    loss_val_running = 0\n",
        "    total_val_data = 0\n",
        "    autoencoder.train()\n",
        "    for X in train_loader:\n",
        "      X = X.to(DEVICE)\n",
        "      optimizer.zero_grad()\n",
        "      output = autoencoder(X)[0]\n",
        "      loss = criterion(output, X)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      loss_train_running += loss.item()*X.size(0)\n",
        "      total_train_data += X.size(0)\n",
        "    train_losses.append(loss_train_running/total_train_data)\n",
        "    autoencoder.eval()\n",
        "    for X_ in val_loader:\n",
        "      X_ = X_.to(DEVICE)\n",
        "      with torch.no_grad():\n",
        "        output_ = autoencoder(X_)[0]\n",
        "        loss_ = criterion(output_, X_)\n",
        "      loss_val_running += loss_.item()*X_.size(0)\n",
        "      total_val_data += X_.size(0)\n",
        "    val_losses.append(loss_val_running/total_val_data)\n",
        "    if val_losses[-1]< best_loss:\n",
        "      best_loss = val_losses[-1]\n",
        "      best_model_wts = autoencoder.state_dict()\n",
        "    clear_output(True)\n",
        "    plot_gallery(output_[:10].cpu().numpy().transpose(0, 2, 3, 1), IMAGE_H, IMAGE_W, n_row=2, n_col=3)\n",
        "    plot_gallery(X_[:10].cpu().numpy().transpose(0, 2, 3, 1), IMAGE_H, IMAGE_W, n_row=2, n_col=3)\n",
        "    plt.show()\n",
        "    print(\"epoch: {} out of {}\".format(epoch+1, epochs))\n",
        "    print(\"train_loss: {}\\t val_loss:{}\".format(train_losses[-1], val_losses[-1]))\n",
        "  autoencoder.load_state_dict(best_model_wts)\n",
        "  return autoencoder, train_losses, val_losses"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFiAE78zdz1a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_param, train_losses, val_losses = train(val_loader, train_loader, 50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDXqryqDIMiw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(train_losses, label = 'train')\n",
        "plt.plot(val_losses, label = 'val')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMmQcEQg5xbw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(best_param.state_dict(), '/content/drive/My Drive/Autoencoder/Autoencoder_50.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nLas7GDC0dS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "autoencoder.load_state_dict(torch.load('/content/drive/My Drive/Autoencoder/Autoencoder_50.pth'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAztAMA4YY7q",
        "colab_type": "text"
      },
      "source": [
        "Давайте посмотрим, как наш тренированный автоэекодер кодирует и восстанавливает картинки:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1J__yvxYY7r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "  real = next(iter(val_loader))\n",
        "  output1 = autoencoder.encoder_(real.to(DEVICE))\n",
        "  output = autoencoder.decoder_(z.to(DEVICE))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMEOJ7oHsDpn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_gallery([output[3].cpu().numpy().transpose(1, 2, 0), real[3].cpu().numpy().transpose(1, 2, 0)], IMAGE_H, IMAGE_W, 1, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OPh9O6UYY7s",
        "colab_type": "text"
      },
      "source": [
        "Not bad, right? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFi96giuYY7t",
        "colab_type": "text"
      },
      "source": [
        "## Sampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOtUaPNYYY7t",
        "colab_type": "text"
      },
      "source": [
        "Давайте теперь будем не просто брать картинку, прогонять ее через автоэекодер и получать реконструкцию, а попробуем создать что-то НОВОЕ\n",
        "\n",
        "Давайте возьмем и подсунем декодеру какие-нибудь сгенерированные нами векторы (например, из нормального распределения) и посмотрим на результат реконструкции декодера:\n",
        "\n",
        "#### If that doesn't work\n",
        "Если вместо лиц у вас выводится непонятно что, попробуйте посмотреть, как выглядят латентные векторы картинок из датасета. Так как в обучении нейронных сетей есть определенная доля рандома, векторы латентного слоя могут быть распределены НЕ как np.random.randn(25, <latent_space_dim>). А чтобы у нас получались лица при запихивании вектора декодеру, вектор должен быть распределен так же, как лаьентные векторы реальных фоток. Так что ридется рандом подогнать."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "8IZykARRYY7u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# сгенерируем 25 рандомных векторов размера latent_space\n",
        "z = torch.randn(25, 250)\n",
        "with torch.no_grad():\n",
        "  autoencoder.eval()\n",
        "  output = autoencoder.decoder_(z.to(DEVICE))\n",
        "  plot_gallery(output.cpu().numpy().transpose(0, 2, 3, 1), IMAGE_H, IMAGE_W, n_row=5, n_col=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "Ey8dD9s0YY7w",
        "colab_type": "text"
      },
      "source": [
        "## Congrats!\n",
        "\n",
        "Time to make fun!\n",
        "\n",
        "Давайте научимся пририсовывать людям улыбки =)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1v-8WwuYY7w",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://i.imgur.com/tOE9rDK.png\" alt=\"linear\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGE0M2GDYY7x",
        "colab_type": "text"
      },
      "source": [
        "План такой:\n",
        "\n",
        "1) Нужно выделить \"вектор улыбки\": для этого нужно из выборки изображений найти несколько (~15 сойдет) людей с улыбками и столько же без.\n",
        "\n",
        "Найти людей с улыбками вам поможет файл с описанием датасета, скачанный вместе с датасетом. В нем указаны имена картинок и присутствубщие атрибуты (улыбки, очки...)\n",
        "\n",
        "2) Вычислить латентный вектор для всех улыбающихся людей (прогнать их через encoder) и то же для всех грустненьких\n",
        "\n",
        "3) Вычислить, собственно, вектор улыбки -- посчитать разность между средним латентным вектором улыбающихся людей и средним латентным вектором грустных людей\n",
        "\n",
        "3) А теперь приделаем улыбку грустному человеку: добавим полученный в пункте 3 вектор к латентному вектору грустного чувака и прогоним полученный вектор через decoder. Получим того же человека, но уже не грустненького!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxqhLxE6PFnl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attrs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91kkEFEQGdBL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_new_face(image, attr = 'Smiling'):\n",
        "\n",
        "  id_new_positive_woman = attrs[attr].sort_values(ascending = False).head(15).index.values\n",
        "  id_new_positive_man = attrs[attrs['Male'] > 0][attr].sort_values(ascending = False).head(15).index.values\n",
        "  id_new_positive = np.concatenate((id_smile_woman, id_smile_man), 0)\n",
        "  id_negative_woman = attrs[attrs['Male'] < 0][attr].sort_values(ascending = True).head(15).index.values\n",
        "  id_negative_man =  attrs[attrs['Male'] > 0][attr].sort_values(ascending = True).head(15).index.values\n",
        "  id_new_negative = np.concatenate((id_s, id_s_1), 0)\n",
        "\n",
        "  autoencoder.eval()\n",
        "  \n",
        "  positive = AutoEncode(data[id_new_positive])\n",
        "  negative = AutoEncode(data[id_new_negative])\n",
        "  positive_loader = DataLoader(positive, 30, shuffle=True)\n",
        "  negative_loader = DataLoader(negative, 30, shuffle = True)\n",
        "  human = torch.FloatTensor(image.transpose(2, 0, 1)/255.).unsqueeze_(0)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    positive_latent = autoencoder.encoder_(next(iter(positive_loader)).to(DEVICE))\n",
        "    negative_latent = autoencoder.encoder_(next(iter(negative_loader)).to(DEVICE))\n",
        "    latent_mean = (torch.mean(positive_latent, axis=0)-torch.mean(negative_latent, axis=0)).unsqueeze_(0)\n",
        "    human_latent = autoencoder.encoder_(human.to(DEVICE))\n",
        "    new_human = autoencoder.decoder_(latent_mean + human_latent)\n",
        "  plot_gallery([new_human.cpu().numpy().transpose(0, 2, 3, 1), human.cpu().numpy().transpose(0, 2, 3, 1)], IMAGE_H, IMAGE_W, 1, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uznwLRIEZdJI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for sad in id_sad:\n",
        "  plot_new_face(data[sad])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXI6jprOYY7z",
        "colab_type": "text"
      },
      "source": [
        "Вуаля! Вы восхитительны!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2UAf0bpYY70",
        "colab_type": "text"
      },
      "source": [
        "Теперь вы можете пририсовывать людям не только улыбки, но и много чего другого -- закрывать/открывать глаза, пририсовывать очки... в общем, все, на что хватит фантазии)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIYuKFwijN2U",
        "colab_type": "text"
      },
      "source": [
        "# Conditional Autoencoder (3 балла)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4ABYDnLMe1e",
        "colab_type": "text"
      },
      "source": [
        "Мы уже научились обучать обычный AE на датасете картинок и получать новые картинки, используя генерацию шума и декодер. \n",
        "Давайте теперь допустим, что мы обучили AE на датасете MNIST и теперь хотим генерировать новые картинки с числами с помощью декодера (как выше мы генерили рандомные лица). \n",
        "И вот мне понадобилось сгенерировать цифру 8. И я подставляю разные варианты шума, и все никак не генерится восьмерка -- у меня получаются то пятерки, то тройки, то четверки. Гадость(\n",
        "\n",
        "  Хотелось бы добавить к нашему AE функцию \"выдай мне пожалуйста рандомное число из вот этого вот класса\", где классов десять (цифры от 0 до 9 образуют десять классов).\n",
        "  Типа я такая говорю \"выдай мне случайную восьмерку\" и оно генерит случайную восьмерку!\n",
        "\n",
        "Conditional AE -- так называется вид автоэнкодера, который предоставляет такую возможность. Ну, название \"conditional\" уже говорит само за себя.\n",
        "\n",
        "И в этой части проекта мы научимся такие обучать."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSp3u2vmuMiQ",
        "colab_type": "text"
      },
      "source": [
        "## Архитектура\n",
        "\n",
        "На картинке ниже представлена архитектура простого Conditional AE.\n",
        "\n",
        "По сути, единственное отличие от обычного -- это то, что мы вместе с картинкой в первом слое энкодера и декодера передаем еще информацию о классе картинки. \n",
        "\n",
        "То есть, в первый (входной) слой энкодера есть конкатенация картинки и информации о классе (например, вектора из девяти нулей и одной единицы). Первый слой декодера есть конкатенация латентного вектора и информации о классе."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5Xu3YuUrjGX",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "![alt text](https://i.ibb.co/2tsWknB/Screen-Shot-2020-01-15-at-9-02-15-PM.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1gA28KVvT5Z",
        "colab_type": "text"
      },
      "source": [
        "Таким образом, при генерации новой рандомной картинки мы должны будем передать декодеру сконкатенированные латентный вектор и класс картинки."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJa6QD87vqm8",
        "colab_type": "text"
      },
      "source": [
        "### P.S.\n",
        "Можно ередавать класс картинки не только в первый слой, но и в каждый слой сети. То есть на каждом слое конкатенировать выход из предыдущего слоя и информацию о классе."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ICnlbsAt6Vt",
        "colab_type": "text"
      },
      "source": [
        "### Датасет\n",
        "\n",
        "Как вы уже догадались, здесь мы будем использовать датасет MNIST (http://yann.lecun.com/exdb/mnist/)\n",
        "\n",
        "Если он вам очень не нравится, можете загуглить любой другой, в котором будет четкое разделение картинок по классам."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvn50Lf_v2j9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor()])\n",
        "\n",
        "trainset = datasets.MNIST(root='./data', train=True, \n",
        "                                      download=True, transform=transform)\n",
        "trainloader = DataLoader(trainset, batch_size=64,\n",
        "                                          shuffle=True)\n",
        "\n",
        "valset = datasets.MNIST(root='./data', train=False,\n",
        "                                     download=True, transform=transform)\n",
        "valloader = DataLoader(valset, batch_size=64,\n",
        "                        shuffle=False)\n",
        "classes = tuple(str(i) for i in range(10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBv1-9CMiaPS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "next(iter(trainloader))[0][10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXIhtWmj98hl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_weights(m):\n",
        "    if type(m) == nn.Conv2d or type(m) == nn.ConvTranspose2d:\n",
        "      nn.init.xavier_uniform_(m.weight)\n",
        "\n",
        "class Autoencoder_MNIST(nn.Module):\n",
        "    def __init__(self, latent=250):\n",
        "        super().__init__()\n",
        "        self.latent = latent\n",
        "        #на вход (28, 28)+ one_hot\n",
        "        self.fc_encode = nn.Sequential(nn.Linear(28*28, 28*28),\n",
        "                                 nn.LeakyReLU(0.2))#попробовать поменять на sigmoid\n",
        "        #выход (28,28)\n",
        "        self.conv1_down = nn.Sequential(nn.Conv2d(1, 20, 3, padding=1),\n",
        "                                        nn.BatchNorm2d(20),\n",
        "                                        nn.LeakyReLU(0.2),\n",
        "        )\n",
        "        self.conv2_down = nn.Sequential(nn.Conv2d(20, 40, 3),\n",
        "                                        nn.BatchNorm2d(40),\n",
        "                                        nn.LeakyReLU(0.2),\n",
        "                                        nn.MaxPool2d(2)\n",
        "        ) \n",
        "        self.conv3_down = nn.Sequential(nn.Conv2d(40, 60, 3),\n",
        "                                        nn.BatchNorm2d(60),\n",
        "                                        nn.LeakyReLU(0.2),\n",
        "        )\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.fc1 = nn.Linear(60*5*5, latent)\n",
        "        #выход 250\n",
        "        self.fc2 = nn.Sequential(nn.Linear(latent, 60*5*5),\n",
        "                                 nn.LeakyReLU(0.2)\n",
        "        )\n",
        "        self.conv3_up = nn.Sequential(nn.ConvTranspose2d(60, 40, 3, stride=2),\n",
        "                                      nn.BatchNorm2d(40),# формула size+(size-1) + (pad)*2 - (kernel-1), где pad = 0, если padding=2, 1, если 1, 2, если 0 и еще padding зависит от kernel (pad = 2 для 3, pad=3 для 4)\n",
        "                                      nn.LeakyReLU(0.2)\n",
        "\n",
        "        )\n",
        "        self.conv2_up = nn.Sequential(nn.ConvTranspose2d(40, 20, 3, stride = 1),\n",
        "                                      nn.BatchNorm2d(20),\n",
        "                                      nn.LeakyReLU(0.2)\n",
        "        )\n",
        "        self.conv1_up = nn.Sequential(nn.ConvTranspose2d(20, 10, 3, stride=1),\n",
        "                                      nn.BatchNorm2d(10),\n",
        "                                      nn.LeakyReLU(0.2),\n",
        "                                      nn.ConvTranspose2d(10, 5, 3, stride=2, padding = 1),\n",
        "                                      nn.BatchNorm2d(5),\n",
        "                                      nn.LeakyReLU(0.2),\n",
        "                                      nn.Conv2d(5, 1, 4, padding=1)\n",
        "        )\n",
        "\n",
        "\n",
        "    def encoder_(self, x, y):\n",
        "        x = self.fc_encode(x + y).view(-1, 1, 28, 28) # попробовать конкатенировать, а не прибавлять\n",
        "        self.conv1 = self.conv1_down(x)\n",
        "        self.conv2 = self.conv2_down(self.conv1)\n",
        "        self.conv3 = self.conv3_down(self.conv2)\n",
        "        latent_code = torch.tanh(self.fc1(self.pool(self.conv3).view(x.size(0), -1)))\n",
        "        return latent_code\n",
        "\n",
        "\n",
        "    def decoder_(self, z, y):\n",
        "        z = self.fc2(z + y).view(-1, 60, 5, 5) # попробовать конкатенировать, а не прибавлять\n",
        "        z = self.conv3_up(z)\n",
        "        z = self.conv2_up(z)\n",
        "        z = self.conv1_up(z)\n",
        "        reconstruct = torch.sigmoid(z) \n",
        "        return reconstruct   \n",
        "\n",
        "    def forward(self, x, y1, y2):\n",
        "        encoder = self.encoder_(x, y1)\n",
        "        decoder = self.decoder_(encoder, y2)\n",
        "        return decoder, encoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtZX7AuuVf5K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Latent = 10\n",
        "DEVICE = torch.device('cuda')\n",
        "autoencoder_mnist = Autoencoder_MNIST(Latent).to(DEVICE)\n",
        "autoencoder_mnist.apply(init_weights)\n",
        "optimizer = optim.Adam(autoencoder_mnist.parameters())\n",
        "criterion = nn.MSELoss()\n",
        "#summary(autoencoder, (30, 28*28))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVd22kRTa009",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def OneHot(batch, data, dim):\n",
        "  massive = np.zeros((batch, dim))\n",
        "  data = pd.Series(np.array(data.cpu()), index = np.arange(len(data)))\n",
        "  massive[np.array(data.index), np.array(data)] = 1\n",
        "  return torch.IntTensor(massive)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBmTZReSZRkL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(val, train, epochs):\n",
        "  train_losses = []\n",
        "  val_losses = []\n",
        "  best_model_wts = autoencoder_mnist.state_dict()\n",
        "  best_loss = np.inf\n",
        "  for epoch in range(epochs):\n",
        "    loss_train_running = 0\n",
        "    total_train_data = 0\n",
        "    loss_val_running = 0\n",
        "    total_val_data = 0\n",
        "    autoencoder_mnist.train()\n",
        "    for X, y in trainloader:\n",
        "      X = X.to(DEVICE)\n",
        "      optimizer.zero_grad()\n",
        "      output = autoencoder_mnist(X.view(-1, 28*28).to(DEVICE), OneHot(len(X), y, 28*28).to(DEVICE), OneHot(len(X), y, Latent).to(DEVICE))[0]\n",
        "      loss = criterion(output, X)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      loss_train_running += loss.item()*X.size(0)\n",
        "      total_train_data += X.size(0)\n",
        "    train_losses.append(loss_train_running/total_train_data)\n",
        "    autoencoder_mnist.eval()\n",
        "    for X_, y_ in valloader:\n",
        "      X_ = X_.to(DEVICE)\n",
        "      with torch.no_grad():\n",
        "        output_ = autoencoder_mnist(X_.view(-1, 28*28).to(DEVICE), OneHot(len(X_), y_, 28*28).to(DEVICE), OneHot(len(X_), y_, Latent).to(DEVICE))[0]\n",
        "        loss_ = criterion(output_, X_)\n",
        "      loss_val_running += loss_.item()*X_.size(0)\n",
        "      total_val_data += X_.size(0)\n",
        "    val_losses.append(loss_val_running/total_val_data)\n",
        "    if val_losses[-1]< best_loss:\n",
        "      best_loss = val_losses[-1]\n",
        "      best_model_wts = autoencoder_mnist.state_dict()\n",
        "    clear_output(True)\n",
        "    plt.imshow(output_[-1].squeeze_(0).cpu().numpy(), cmap='gray')\n",
        "    plt.show()\n",
        "    plt.imshow(X_[-1].squeeze_(0).cpu().numpy(), cmap='gray')\n",
        "    plt.show()\n",
        "    sampling(1)\n",
        "    print(\"epoch: {} out of {}\".format(epoch+1, epochs))\n",
        "    print(\"train_loss: {}\\t val_loss:{}\".format(train_losses[-1], val_losses[-1]))\n",
        "  autoencoder_mnist.load_state_dict(best_model_wts)\n",
        "  return autoencoder_mnist, train_losses, val_losses"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4fNwP5bhmj1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best, train_losses, val_losses = train(valloader, trainloader, 30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gnx_M4_F2LGJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#torch.save(best.state_dict(), '/content/drive/My Drive/Autoencoder/Autoencoder_50_mnist.pth')\n",
        "autoencoder_mnist.load_state_dict(torch.load('/content/drive/My Drive/Autoencoder/Autoencoder_50_mnist.pth'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxVAEW0ywF6W",
        "colab_type": "text"
      },
      "source": [
        "## Sampling\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyV0vcFiwTDO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sampling(number):\n",
        "  z = torch.randn(1, Latent)*0.1\n",
        "  condition = OneHot(1, torch.IntTensor([number]), Latent)\n",
        "  with torch.no_grad():\n",
        "    autoencoder_mnist.eval()\n",
        "    output = autoencoder_mnist.decoder_(z.to(DEVICE), condition.to(DEVICE))\n",
        "    plt.imshow(output.squeeze_(0)[0].cpu().numpy(), cmap='gray')\n",
        "    plt.show()\n",
        "for i in range(10):\n",
        "  sampling(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnxBdgmE0lMG",
        "colab_type": "text"
      },
      "source": [
        "Splendid! Вы великолепны!\n",
        "\n",
        "Теперь давайте сделаем следующее: посмотрим на то, как выглядит латентное пространство векторов, соответствующих нашим картинкам. \n",
        "Для этого вам нужно:\n",
        "1.  прогнать картинки из датасета через encoder, получить латентные векторы\n",
        "2. Прогнать векторы через TSNE, получить их двумерную проекцию\n",
        "3. Изобразить полученные после TSNE двумерные векторы на плоскости с помощью plt.scatter, покрасив точки в цвета в зависимости от класса картинки, которой она соответствует. (как красить точки, см. в документации к plt.scatter). \n",
        "4. Подумать, что вы видите и записать свои мысли"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYHggDEZMuUU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://anaconda.org/CannyLab/tsnecuda/2.1.0/download/linux-64/tsnecuda-2.1.0-cuda100.tar.bz2\n",
        "!tar xvjf tsnecuda-2.1.0-cuda100.tar.bz2\n",
        "!cp -r site-packages/* /usr/local/lib/python3.6/dist-packages/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAQbiJfvNSm_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!echo $LD_LIBRARY_PATH \n",
        "# this is probably /usr/lib64-nvidia\n",
        "\n",
        "!ln -s /content/lib/libfaiss.so $LD_LIBRARY_PATH/libfaiss.so"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aylvuymY2dwl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "autoencoder_mnist.eval()\n",
        "output = np.array((64*10)*[]).reshape(-1, 10)\n",
        "labels = np.array((64*[]))\n",
        "with torch.no_grad():\n",
        "  for X, y in trainloader:\n",
        "    output = np.concatenate((autoencoder_mnist.encoder_(X.view(-1, 28*28).to(DEVICE), OneHot(len(X), y, 28*28).to(DEVICE)).cpu().numpy(), output), axis = 0)\n",
        "    labels = np.concatenate((y.cpu().numpy(), labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yae7R4QzNaNY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tsnecuda\n",
        "tsnecuda.test()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xB55W0VrNp4H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tsnecuda import TSNE as TSNE_CUDA\n",
        "tsne_cuda = TSNE_CUDA(\n",
        "    n_components=2, \n",
        "    perplexity=30.0, \n",
        "    early_exaggeration=12.0, \n",
        "    learning_rate=200.0, \n",
        "    n_iter=1000, \n",
        "    n_iter_without_progress=300, \n",
        "    min_grad_norm=1e-07, \n",
        "    metric='euclidean', \n",
        "    init='random', \n",
        "    verbose=0,\n",
        "    random_seed=None, # different parameter name\n",
        "    theta=0.5 # different parameter name\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rz4ludtcOEGW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scale = StandardScaler()\n",
        "scaled = scale.fit_transform(output[:4000])\n",
        "result = tsne_cuda.fit_transform(scaled)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xSiBr5VSj5W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.DataFrame(result, index = labels[:4000])\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nl2W24xwCp_6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "\n",
        "colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k', '0.6', '0.3', '0.5']\n",
        "for i in range(10):\n",
        "  ax.scatter(data.loc[i][0].values, data.loc[i][1].values, c=colors[i], label = i)\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_Y5iVuu2kJ2",
        "colab_type": "text"
      },
      "source": [
        "<тут ваши мысли по поводу того, что вы видите на рисунке>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQnEGmknYY71",
        "colab_type": "text"
      },
      "source": [
        "# BONUS 1. (2 балла) \n",
        "### Variational Autoencoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWQNRjJq2uTz",
        "colab_type": "text"
      },
      "source": [
        "Если вы (надеюсь) осознали, в каком месте у conditional AE выше могли бы быть проблемы, то -- тадам!!\n",
        "\n",
        "Представляю вам проапгрейдженную версию автоэнкодеров -- вариационные автоэнкодеры."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nb5AHMcxYY73",
        "colab_type": "text"
      },
      "source": [
        "https://towardsdatascience.com/intuitively-understanding-variational-autoencoders-1bfe67eb5daf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoNVT5tYYY74",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self, latent = 10, dim = 28):\n",
        "        super().__init__()\n",
        "        self.latent = latent\n",
        "        self.hid = int((int((dim-2)/2)-2)/2)\n",
        "\n",
        "        self.conv1_down = nn.Sequential(nn.Conv2d(1, 10, 3, padding=1),\n",
        "                                        nn.BatchNorm2d(10, 1e-3),\n",
        "                                        nn.ReLU(),\n",
        "        )\n",
        "        self.conv2_down = nn.Sequential(nn.Conv2d(10, 20, 3),\n",
        "                                        nn.BatchNorm2d(20, 1e-3),\n",
        "                                        nn.ReLU(),\n",
        "                                        nn.MaxPool2d(2)\n",
        "        ) \n",
        "        self.conv3_down = nn.Sequential(nn.Conv2d(20, 40, 3),\n",
        "                                        nn.BatchNorm2d(40, 1e-3),\n",
        "                                        nn.ReLU(),\n",
        "        )\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.fc_mu = nn.Linear(40*self.hid*self.hid, self.latent)\n",
        "        self.fc_logsigma = nn.Linear(40*self.hid*self.hid, self.latent)\n",
        "\n",
        "        #выход 250\n",
        "        self.fc2 = nn.Sequential(nn.Linear(self.latent, 40*self.hid*self.hid)\n",
        "        )\n",
        "        self.conv3_up = nn.Sequential(nn.ConvTranspose2d(40, 20, 3, stride=2),\n",
        "                                      nn.BatchNorm2d(20, 1e-3),# формула size+(size-1) + (pad)*2 - (kernel-1), где pad = 0, если padding=2, 1, если 1, 2, если 0 и еще padding зависит от kernel (pad = 2 для 3, pad=3 для 4)\n",
        "                                      nn.ReLU()\n",
        "\n",
        "        )\n",
        "        self.conv2_up = nn.Sequential(nn.ConvTranspose2d(20, 20, 3, stride = 1),\n",
        "                                      nn.BatchNorm2d(20, 1e-3),\n",
        "                                      nn.ReLU()\n",
        "        )\n",
        "        self.conv1_up = nn.Sequential(nn.ConvTranspose2d(20, 10, 3, stride=1),\n",
        "                                      nn.BatchNorm2d(10, 1e-3),\n",
        "                                      nn.ReLU(),\n",
        "                                      nn.ConvTranspose2d(10, 5, 3, stride=2, padding = 1),\n",
        "                                      nn.BatchNorm2d(5, 1e-3),\n",
        "                                      nn.ReLU(),\n",
        "                                      nn.Conv2d(5, 1, 4, padding=1)\n",
        "        )\n",
        "\n",
        "\n",
        "    def encode(self, x):\n",
        "        self.conv1 = self.conv1_down(x)\n",
        "        self.conv2 = self.conv2_down(self.conv1)\n",
        "        self.conv3 = self.conv3_down(self.conv2)\n",
        "        mu = self.fc_mu(self.pool(self.conv3).view(x.size(0), -1))\n",
        "        logsigma = self.fc_logsigma(self.pool(self.conv3).view(x.size(0), -1))\n",
        "        return mu, logsigma\n",
        "    \n",
        "\n",
        "    def gaussian_sampler(self, mu, logsigma):\n",
        "        \"\"\"\n",
        "        Функция сэмплирует латентные векторы из нормального распределения с параметрами mu и sigma\n",
        "        \"\"\"\n",
        "        std = torch.exp(logsigma*0.5)\n",
        "        esp = torch.randn(*mu.size()).to(DEVICE)\n",
        "        return mu + std * esp\n",
        "    \n",
        "\n",
        "    def decode(self, z):\n",
        "        z = self.fc2(z).view(-1, 40, self.hid, self.hid)\n",
        "        z = self.conv3_up(z)\n",
        "        z = self.conv2_up(z)\n",
        "        z = self.conv1_up(z)\n",
        "        reconstruct = torch.sigmoid(z) \n",
        "        return reconstruct\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logsigma = self.encode(x)\n",
        "        z = self.gaussian_sampler(mu, logsigma)\n",
        "        reconstruction = self.decode(z)\n",
        "        return mu, logsigma, reconstruction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAB77d-PYY76",
        "colab_type": "text"
      },
      "source": [
        "Определим лосс и его компоненты для VAE:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ac5ey7uIYY77",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def KL_divergence(mu, logsigma):\n",
        "    \"\"\"\n",
        "    часть функции потерь, которая отвечает за \"близость\" латентных представлений разных людей\n",
        "    \"\"\"\n",
        "    return -(0.5) * torch.sum(1 + logsigma - mu**2 - torch.exp(logsigma))\n",
        "\n",
        "def log_likelihood(x, reconstruction):\n",
        "    \"\"\"\n",
        "    часть функции потерь, которая отвечает за качество реконструкции (как mse в обычном autoencoder)\n",
        "    \"\"\"\n",
        "    return F.binary_cross_entropy(reconstruction, x, reduction='sum')\n",
        "\n",
        "def loss_vae(x, mu, logsigma, reconstruction):\n",
        "    return KL_divergence(mu, logsigma) + log_likelihood(x, reconstruction)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPJQu70eYY79",
        "colab_type": "text"
      },
      "source": [
        "И обучим модель:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtCjfqXdYY79",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DEVICE = torch.device('cuda')\n",
        "\n",
        "autoencoder_vae = VAE(10).to(DEVICE)\n",
        "#autoencoder_vae.apply(init_weights)\n",
        "\n",
        "optimizer = optim.Adam(autoencoder_vae.parameters(), lr = 1e-4)\n",
        "\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.8)\n",
        "\n",
        "summary(autoencoder_vae, (1, 28, 28))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "rY1khca6YY7_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.autograd.set_detect_anomaly(True)\n",
        "def train(val, train, epochs):\n",
        "  train_losses = []\n",
        "  val_losses = []\n",
        "  best_model_wts = autoencoder_vae.state_dict()\n",
        "  best_loss = np.inf\n",
        "  for epoch in range(epochs):\n",
        "    loss_train_running = 0\n",
        "    total_train_data = 0\n",
        "    loss_val_running = 0\n",
        "    total_val_data = 0\n",
        "    autoencoder_vae.train()\n",
        "    for X, _ in trainloader:\n",
        "      X = X.to(DEVICE)\n",
        "      optimizer.zero_grad()\n",
        "      mu, logsigma, output = autoencoder_vae(X)\n",
        "      loss = loss_vae(X,mu, logsigma, output)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      loss_train_running += loss.item()*X.size(0)\n",
        "      total_train_data += X.size(0)\n",
        "    train_losses.append(loss_train_running/total_train_data)\n",
        "    autoencoder_vae.eval()\n",
        "    for X_, _ in valloader:\n",
        "      X_ = X_.to(DEVICE)\n",
        "      with torch.no_grad():\n",
        "        mu_, logsigma_, output_ = autoencoder_vae(X_)\n",
        "        loss_ = loss_vae(X_, mu_, logsigma_, output_)\n",
        "      loss_val_running += loss_.item()*X_.size(0)\n",
        "      total_val_data += X_.size(0)\n",
        "    print(torch.mean(mu_), torch.mean(logsigma_))\n",
        "    val_losses.append(loss_val_running/total_val_data)\n",
        "    if val_losses[-1]< best_loss:\n",
        "      best_loss = val_losses[-1]\n",
        "      best_model_wts = autoencoder_vae.state_dict()\n",
        "    #scheduler.step()\n",
        "    clear_output(True)\n",
        "    plt.imshow(output_[-1].squeeze_(0).cpu().numpy(), cmap='gray')\n",
        "    plt.show()\n",
        "    plt.imshow(X_[-1].squeeze_(0).cpu().numpy(), cmap='gray')\n",
        "    plt.show()\n",
        "    sample()\n",
        "    print(\"epoch: {} out of {}\".format(epoch+1, epochs))\n",
        "    print(\"train_loss: {}\\t val_loss:{}\".format(train_losses[-1], val_losses[-1]))\n",
        "  autoencoder_vae.load_state_dict(best_model_wts)\n",
        "  return autoencoder_vae, train_losses, val_losses"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xu0ZQIhbYad6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_vae, train_losses, val_losses = train(valloader, trainloader, 50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "scrolled": true,
        "id": "SkxW_8fkYY8B",
        "colab_type": "text"
      },
      "source": [
        "Давайте посмотрим, как наш тренированный VAE кодирует и восстанавливает картинки:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RijP_UCfpMN1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(best_vae.state_dict(), '/content/drive/My Drive/Autoencoder/Autoencoder_vae_mnist.pth')\n",
        "autoencoder_vae.load_state_dict(torch.load('/content/drive/My Drive/Autoencoder/Autoencoder_vae_mnist.pth'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0jI-FKEYY8E",
        "colab_type": "text"
      },
      "source": [
        "And finally sample from VAE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po-KV8E8YY8F",
        "colab_type": "text"
      },
      "source": [
        "## Sampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQXYIXjoYY8F",
        "colab_type": "text"
      },
      "source": [
        "Давайте попробуем проделать для VAE то же, что и с обычным автоэнкодером -- подсунуть decoder'у из VAE случайные векторы из нормального распределения и посмотреть, какие лица получатся:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOhhH-osYY8G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# вспомните про замечание из этого же ункта обычного AE про распределение латентных переменных\n",
        "def sample():\n",
        "  z = torch.randn(1, 10)\n",
        "  autoencoder_vae.eval()\n",
        "  with torch.no_grad():\n",
        "    output = autoencoder_vae.decode(z.to(DEVICE))\n",
        "  plt.imshow(output.cpu()[0][0].numpy(), cmap='gray')\n",
        "  plt.show()\n",
        "sample()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESPBHrL3YY8H",
        "colab_type": "text"
      },
      "source": [
        "## Congrats v2.0!\n",
        "\n",
        "Как вы уже догадались, здесь тоже можно попробовать пририсовывать разные атрибуты людям. Можно, например, так же пририсовать улыбки и сравнить с тем, как это получалось у обычного автоэнкодера"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tq-hgOk-YY8I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "<как вы уже догадались, тут Ваш код>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7jA3PRvhAv5",
        "colab_type": "text"
      },
      "source": [
        "# BONUS 2. (2 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woSjtsK63Lan",
        "colab_type": "text"
      },
      "source": [
        "А теперь пришло время сделать \n",
        "## Conditional Variational AE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZf-Dr9-hFAt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#проверить код\n",
        "class CVAE(nn.Module):\n",
        "    def __init__(self, latent = 10, dim = 28):\n",
        "        super().__init__()\n",
        "        self.latent = latent\n",
        "        self.dim = dim\n",
        "        self.hid = int((int((dim-2)/2)-2)/2)\n",
        "\n",
        "        self.fc_encode = nn.Sequential(nn.Linear(self.dim**2+10, self.dim**2),\n",
        "                                 nn.LeakyReLU(0.2)\n",
        "        )\n",
        "        self.conv1_down = nn.Sequential(nn.Conv2d(1, 10, 3, padding=1),\n",
        "                                        nn.BatchNorm2d(10, 1e-3),\n",
        "                                        nn.LeakyReLU(0.2),\n",
        "        )\n",
        "        self.conv2_down = nn.Sequential(nn.Conv2d(10, 20, 3),\n",
        "                                        nn.BatchNorm2d(20, 1e-3),\n",
        "                                        nn.LeakyReLU(0.2),\n",
        "                                        nn.MaxPool2d(2)\n",
        "        ) \n",
        "        self.conv3_down = nn.Sequential(nn.Conv2d(20, 40, 3),\n",
        "                                        nn.BatchNorm2d(40, 1e-3),\n",
        "                                        nn.LeakyReLU(0.2),\n",
        "        )\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.fc_mu = nn.Linear(40*self.hid*self.hid, self.latent)\n",
        "        self.fc_logsigma = nn.Linear(40*self.hid*self.hid, self.latent)\n",
        "\n",
        "        #выход 250\n",
        "        self.fc2 = nn.Sequential(nn.Linear(self.latent + 10 , 40*self.hid*self.hid)\n",
        "        )\n",
        "        self.conv3_up = nn.Sequential(nn.ConvTranspose2d(40, 20, 3, stride=2),\n",
        "                                      nn.BatchNorm2d(20, 1e-3),# формула size+(size-1) + (pad)*2 - (kernel-1), где pad = 0, если padding=2, 1, если 1, 2, если 0 и еще padding зависит от kernel (pad = 2 для 3, pad=3 для 4)\n",
        "                                      nn.LeakyReLU(0.2)\n",
        "\n",
        "        )\n",
        "        self.conv2_up = nn.Sequential(nn.ConvTranspose2d(20, 20, 3, stride = 1),\n",
        "                                      nn.BatchNorm2d(20, 1e-3),\n",
        "                                      nn.LeakyReLU(0.2)\n",
        "        )\n",
        "        self.conv1_up = nn.Sequential(nn.ConvTranspose2d(20, 10, 3, stride=1),\n",
        "                                      nn.BatchNorm2d(10, 1e-3),\n",
        "                                      nn.LeakyReLU(0.2),\n",
        "                                      nn.ConvTranspose2d(10, 5, 3, stride=2, padding = 1),\n",
        "                                      nn.BatchNorm2d(5, 1e-3),\n",
        "                                      nn.LeakyReLU(0.2),\n",
        "                                      nn.Conv2d(5, 1, 4, padding=1)\n",
        "        )\n",
        "\n",
        "\n",
        "    def encode(self, x):\n",
        "        x = self.fc_encode(x).view(-1, 1, self.dim, self.dim)\n",
        "        self.conv1 = self.conv1_down(x)\n",
        "        self.conv2 = self.conv2_down(self.conv1)\n",
        "        self.conv3 = self.conv3_down(self.conv2)\n",
        "        mu = self.fc_mu(self.pool(self.conv3).view(x.size(0), -1))\n",
        "        logsigma = self.fc_logsigma(self.pool(self.conv3).view(x.size(0), -1))\n",
        "        return mu, logsigma\n",
        "    \n",
        "\n",
        "    def gaussian_sampler(self, mu, logsigma):\n",
        "        \"\"\"\n",
        "        Функция сэмплирует латентные векторы из нормального распределения с параметрами mu и sigma\n",
        "        \"\"\"\n",
        "        std = torch.exp(logsigma*0.5)\n",
        "        esp = torch.randn(*mu.size()).to(DEVICE)\n",
        "        return mu + std * esp\n",
        "    \n",
        "\n",
        "    def decode(self, z, y):\n",
        "        z = torch.cat((z.view(-1, self.latent), OneHot(z.size(0), y, 10).to(DEVICE)), dim = 1)\n",
        "        z = self.fc2(z).view(-1, 40, self.hid, self.hid)\n",
        "        z = self.conv3_up(z)\n",
        "        z = self.conv2_up(z)\n",
        "        z = self.conv1_up(z)\n",
        "        reconstruct = torch.sigmoid(z) \n",
        "        return reconstruct\n",
        "        \n",
        "\n",
        "    def forward(self, x, y):\n",
        "        mu, logsigma = self.encode(x)\n",
        "        z = self.gaussian_sampler(mu, logsigma)\n",
        "        reconstruction = self.decode(z, y)\n",
        "        return mu, logsigma, reconstruction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyyN42Z3s6MP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DEVICE = torch.device('cuda')\n",
        "Latent = 10\n",
        "\n",
        "autoencoder_cvae = CVAE(Latent).to(DEVICE)\n",
        "#autoencoder_cvae.apply(init_weights)\n",
        "\n",
        "optimizer = optim.Adam(autoencoder_cvae.parameters(), lr = 1e-4)\n",
        "\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.7)\n",
        "\n",
        "#summary(autoencoder_cvae, (64, 28*28+10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiupzZLIuS_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def OneHot(batch, data, dim):\n",
        "  massive = np.zeros((batch, dim))\n",
        "  data = pd.Series(np.array(data.cpu()), index = np.arange(len(data)))\n",
        "  massive[np.array(data.index), np.array(data)] = 1\n",
        "  return torch.FloatTensor(massive)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tXf6wwUuZOk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.autograd.set_detect_anomaly(True)\n",
        "#проверить код\n",
        "def train(val, train, epochs):\n",
        "  train_losses = []\n",
        "  val_losses = []\n",
        "  best_model_wts = autoencoder_cvae.state_dict()\n",
        "  best_loss = np.inf\n",
        "  for epoch in range(epochs):\n",
        "    loss_train_running = 0\n",
        "    total_train_data = 0\n",
        "    loss_val_running = 0\n",
        "    total_val_data = 0\n",
        "    autoencoder_cvae.train()\n",
        "    for X, y in trainloader:\n",
        "      X = X.to(DEVICE)\n",
        "      optimizer.zero_grad()\n",
        "      input = torch.cat((X.view(-1, 28*28), OneHot(X.size(0), y, 10).to(DEVICE)), dim = 1)\n",
        "      mu, logsigma, output = autoencoder_cvae(input.to(DEVICE), y)\n",
        "      loss = loss_vae(X,mu, logsigma, output)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      loss_train_running += loss.item()*X.size(0)\n",
        "      total_train_data += X.size(0)\n",
        "    train_losses.append(loss_train_running/total_train_data)\n",
        "    autoencoder_cvae.eval()\n",
        "    for X_, y_ in valloader:\n",
        "      X_ = X_.to(DEVICE)\n",
        "      with torch.no_grad():\n",
        "        input_ = torch.cat((X_.view(-1, 28*28), OneHot(X_.size(0), y_, 10).to(DEVICE)), dim = 1)\n",
        "        mu_, logsigma_, output_ = autoencoder_cvae(input_.to(DEVICE), y_)\n",
        "        loss_ = loss_vae(X_, mu_, logsigma_, output_)\n",
        "      loss_val_running += loss_.item()*X_.size(0)\n",
        "      total_val_data += X_.size(0)\n",
        "    print(torch.mean(mu_), torch.mean(logsigma_))\n",
        "    val_losses.append(loss_val_running/total_val_data)\n",
        "    if val_losses[-1]< best_loss:\n",
        "      best_loss = val_losses[-1]\n",
        "      best_model_wts = autoencoder_cvae.state_dict()\n",
        "    #scheduler.step()\n",
        "    clear_output(True)\n",
        "    plt.imshow(output_[-1].squeeze_(0).cpu().numpy(), cmap='gray')\n",
        "    plt.show()\n",
        "    plt.imshow(X_[-1].squeeze_(0).cpu().numpy(), cmap='gray')\n",
        "    plt.show()\n",
        "    sampling(4)\n",
        "    print(\"epoch: {} out of {}\".format(epoch+1, epochs))\n",
        "    print(\"train_loss: {}\\t val_loss:{}\".format(train_losses[-1], val_losses[-1]))\n",
        "  autoencoder_cvae.load_state_dict(best_model_wts)\n",
        "  return autoencoder_cvae, train_losses, val_losses"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_quSGnELclAC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_cvae, train_losses, val_losses = train(valloader, trainloader, 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "um3OfA_kTlZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(best_vae.state_dict(), '/content/drive/My Drive/Autoencoder/Autoencoder_cvae.pth')\n",
        "autoencoder_vae.load_state_dict(torch.load('/content/drive/My Drive/Autoencoder/Autoencoder_cvae.pth'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqi_fu69dG4E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sampling(number):\n",
        "  z = torch.randn(1, Latent)\n",
        "  #condition = OneHot(1, torch.IntTensor([number]), Latent) \n",
        "  with torch.no_grad():\n",
        "    autoencoder_cvae.eval()\n",
        "    output = autoencoder_cvae.decode(z.to(DEVICE), torch.IntTensor([number]))\n",
        "    plt.imshow(output.squeeze_(0)[0].cpu().numpy(), cmap='gray')\n",
        "    plt.show()\n",
        "for i in range(10):\n",
        "  sampling(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rt2S77cm3O1v",
        "colab_type": "text"
      },
      "source": [
        "... и так же посмотреть на латентное пространство векторов VAE, как мы делали это с обычным variational AE, понять, чем же оно отличается и сделать выводы:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSCYK7sH3KEc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "<тут код>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ET8IELWu3Z2c",
        "colab_type": "text"
      },
      "source": [
        "<тут выводы>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KN3D_k5W_WZz",
        "colab_type": "text"
      },
      "source": [
        "# BONUS 3. (2 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12a1jkpkCsIU",
        "colab_type": "text"
      },
      "source": [
        "У автоэнкодеров, кроме сжатия и генерации изображений, есть другие практические применения. Про одно из них это бонксное задание."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8EN-8jlCtmd",
        "colab_type": "text"
      },
      "source": [
        "Автоэнкодеры могут быть использованы для избавления от шума на фотографиях (denoising). Для этого их нужно обучить специальным образом: input картинка будет зашумленной, а выдавать автоэнкодер должен будет картинку без шума. \n",
        "То есть, loss-функция AE останется той же (MSE между реальной картинкой и выданной), а на вход автоэнкодеру будет подаваться зашумленная картинка."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysI0BCuRDbvm",
        "colab_type": "text"
      },
      "source": [
        "Для того, чтобы поставить эксперимент, нужно взять ваш любимый датасет (датасет лиц или MSE с прошлых заданий или любой другой) и сделать копию этого датасета с шумом. \n",
        "\n",
        "В питоне шум можно добавить так:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5e746iVDgSm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DEVICE = torch.device('cuda')\n",
        "autoencoder = Autoencoder_2().to(DEVICE)\n",
        "autoencoder.apply(init_weights)\n",
        "optimizer = optim.Adam(autoencoder.parameters())\n",
        "criterion = nn.MSELoss()\n",
        "summary(autoencoder, (3,45, 45))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fSPkXMtDpd5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(val, train, epochs, noise_factor = 0.1):\n",
        "  train_losses = []\n",
        "  val_losses = []\n",
        "  best_model_wts = autoencoder.state_dict()\n",
        "  best_loss = np.inf\n",
        "  for epoch in range(epochs):\n",
        "    loss_train_running = 0\n",
        "    total_train_data = 0\n",
        "    loss_val_running = 0\n",
        "    total_val_data = 0\n",
        "    autoencoder.train()\n",
        "    for X in train_loader:\n",
        "      X = X.to(DEVICE)\n",
        "      X_noisy = X + noise_factor * torch.randn(*X.size()).to(DEVICE)\n",
        "      optimizer.zero_grad()\n",
        "      output = autoencoder(X_noisy)[0]\n",
        "      loss = criterion(output, X)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      loss_train_running += loss.item()*X.size(0)\n",
        "      total_train_data += X.size(0)\n",
        "    train_losses.append(loss_train_running/total_train_data)\n",
        "    autoencoder.eval()\n",
        "    for X_ in val_loader:\n",
        "      X_ = X_.to(DEVICE)\n",
        "      X_noisy_ = X_ + noise_factor * torch.randn(*X_.size()).to(DEVICE)\n",
        "      with torch.no_grad():\n",
        "        output_ = autoencoder(X_noisy_)[0]\n",
        "        loss_ = criterion(output_, X_)\n",
        "      loss_val_running += loss_.item()*X_.size(0)\n",
        "      total_val_data += X_.size(0)\n",
        "    val_losses.append(loss_val_running/total_val_data)\n",
        "    if val_losses[-1]< best_loss:\n",
        "      best_loss = val_losses[-1]\n",
        "      best_model_wts = autoencoder.state_dict()\n",
        "    clear_output(True)\n",
        "    plot_gallery(output_[:10].cpu().numpy().transpose(0, 2, 3, 1), IMAGE_H, IMAGE_W, n_row=2, n_col=3)\n",
        "    plot_gallery(np.clip(X_noisy_[:10].cpu().numpy().transpose(0, 2, 3, 1), 0, 1), IMAGE_H, IMAGE_W, n_row=2, n_col=3)\n",
        "    plt.show()\n",
        "    print(\"epoch: {} out of {}\".format(epoch+1, epochs))\n",
        "    print(\"train_loss: {}\\t val_loss:{}\".format(train_losses[-1], val_losses[-1]))\n",
        "  autoencoder.load_state_dict(best_model_wts)\n",
        "  return autoencoder, train_losses, val_losses"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B03NQ_sKDvg2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_param, train_losses, val_losses = train(val_loader, train_loader, 50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATYG1UJ_anlJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(best_param.state_dict(), '/content/drive/My Drive/Autoencoder/Autoencoder_noise.pth')\n",
        "autoencoder.load_state_dict(torch.load('/content/drive/My Drive/Autoencoder/Autoencoder_noise.pth'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qA5xi_AvRjrU",
        "colab_type": "text"
      },
      "source": [
        "# Bonus 4. (2+ балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHEYlsVHRzIE",
        "colab_type": "text"
      },
      "source": [
        "Пишем телеграм-бота!\n",
        "\n",
        "Можно написать телеграм-бота, которому на вход вы подаете, например, картинку без улыбки, а он вам возвращает с улыбкой.\n",
        "\n",
        "Или еще много вариантов, чего может уметь делать бот. Придумайте сами)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-KAfd5pLCBS",
        "colab_type": "text"
      },
      "source": [
        "# Эпилог"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDI06AONLYKG",
        "colab_type": "text"
      },
      "source": [
        "здесь мы рассмотрели не все применения автоэнкодеров. Еще есть, например:\n",
        "\n",
        "-- поиск аномалий\n",
        "-- дополнение отсутствующих частей картины\n",
        "-- работа с sequential данными (например, временными рядами)\n",
        "-- гибриды ГАН+АЕ, которые активно изучаются в последнее время\n",
        "-- использование латентных переменных АЕ в качестве фичей\n",
        "...\n",
        "\n",
        "Они не были частью этого проекта, потому что для их реализации пришлось бы больше возиться с датасетами. \n",
        "\n",
        "Но! Если вы хотите, вы, конечно, всегда можете реализовать еще что-то и получить за это еще допбаллы."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBCiWOicLwLI",
        "colab_type": "text"
      },
      "source": [
        "Надеюсь, вам понравилось!"
      ]
    }
  ]
}